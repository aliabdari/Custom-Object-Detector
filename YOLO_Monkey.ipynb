{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_Monkey.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliabdari/Custom-Object-Detector/blob/main/YOLO_Monkey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cphivneT8i5L"
      },
      "outputs": [],
      "source": [
        "!wget \"http://www2.ehub.kyoto-u.ac.jp/datasets/macaquepose/download.php\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/download.php\""
      ],
      "metadata": {
        "id": "4axhqO7-8yTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x -Y \"/content/labels.rar\" \"/content/v1/\" "
      ],
      "metadata": {
        "id": "o5DkRJWS_OpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/ultralytics/yolov5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKDssowhbdXn",
        "outputId": "1175f82b-8b12-4dff-fc4a-c121137a0ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12426, done.\u001b[K\n",
            "remote: Total 12426 (delta 0), reused 0 (delta 0), pack-reused 12426\u001b[K\n",
            "Receiving objects: 100% (12426/12426), 12.36 MiB | 12.22 MiB/s, done.\n",
            "Resolving deltas: 100% (8520/8520), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Aifbt-cNce",
        "outputId": "6dad5723-c6fd-4c85-eb2f-e6d184323803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 640\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "MODEL = \"yolov5s\"\n",
        "WORKERS = 1\n",
        "PROJECT = \"monkey\"\n",
        "RUN_NAME = f\"{MODEL}_size{SIZE}_epochs{EPOCHS}_batch{BATCH_SIZE}_small\"\n"
      ],
      "metadata": {
        "id": "2hW_cpuBcP9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img {SIZE}\\\n",
        "               --batch {BATCH_SIZE}\\\n",
        "               --epochs {EPOCHS}\\\n",
        "               --weights {MODEL}.pt\\\n",
        "               --workers {WORKERS}\\\n",
        "               --project {PROJECT}\\\n",
        "               --name {RUN_NAME}\\\n",
        "               --exist-ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lh2OKlxcl-V",
        "outputId": "7da9bd03-511c-4025-a44d-e9de1862bbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=6, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=1, project=monkey, name=yolov5s_size640_epochs6_batch64_small, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.1-353-g2e10909 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir monkey', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 270 layers, 7022326 parameters, 7022326 gradients\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/v1/labels' images and labels...13083 found, 0 missing, 0 empty, 0 corrupt: 100% 13083/13083 [00:36<00:00, 356.11it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/v1/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/labels' images and labels...0 found, 15 missing, 0 empty, 0 corrupt: 100% 15/15 [00:00<00:00, 639.97it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: No labels found in data/labels.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/labels.cache\n",
            "Plotting labels to monkey/yolov5s_size640_epochs6_batch64_small/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.04 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mmonkey/yolov5s_size640_epochs6_batch64_small\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/5     14.2G   0.06346    0.0238         0        72       640: 100% 205/205 [1:19:38<00:00, 23.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.98it/s]\n",
            "                 all         15          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/5     14.2G   0.04056   0.01666         0        74       640: 100% 205/205 [1:20:20<00:00, 23.51s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.39it/s]\n",
            "                 all         15          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/5     14.2G   0.03333   0.01522         0        81       640: 100% 205/205 [1:20:13<00:00, 23.48s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.32it/s]\n",
            "                 all         15          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       3/5     14.2G    0.0309   0.01498         0       185       640:   7% 15/205 [05:50<1:13:27, 23.20s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,shutil\n",
        "\n",
        "list_images = []\n",
        "for file in os.listdir(\"/content/v1/images\"):\n",
        "    if file.endswith(\".jpg\"):\n",
        "        list_images.append('/content/v1/images' + os.sep + file)"
      ],
      "metadata": {
        "id": "FM4byrWHw-LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4dTNFnL5j2d",
        "outputId": "6a7a353d-4712-41dd-d4c6-24ee94963ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13083"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(list_images)"
      ],
      "metadata": {
        "id": "_Mx7DvCdxpuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_images[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "75vnhTmp5wpZ",
        "outputId": "75c4ca28-32b5-4ffc-db1e-f3768a2bd006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/v1/images/ZooA_3151.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "for f in range(2000):\n",
        "  shutil.copy(list_images[f], '/content/v2/images')"
      ],
      "metadata": {
        "id": "qKw-0qkyx0-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(2000):\n",
        "  text_file = list_images[t].replace('.jpg','.txt').replace('images','labels')\n",
        "  shutil.copy(text_file, '/content/v2/labels')"
      ],
      "metadata": {
        "id": "XrSSeb586auh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img {SIZE}\\\n",
        "               --batch {BATCH_SIZE}\\\n",
        "               --epochs {EPOCHS}\\\n",
        "               --weights {MODEL}.pt\\\n",
        "               --workers {WORKERS}\\\n",
        "               --project {PROJECT}\\\n",
        "               --name {RUN_NAME}\\\n",
        "               --exist-ok"
      ],
      "metadata": {
        "id": "e8Ro2DCU7Shc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5641bbf-ee3f-4980-f22c-50025ee7afd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=1, project=monkey, name=yolov5s_size640_epochs20_batch64_small, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.1-353-g2e10909 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir monkey', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 270 layers, 7022326 parameters, 7022326 gradients\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/v2/labels.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupt: 100% 2000/2000 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/labels' images and labels...0 found, 7 missing, 0 empty, 0 corrupt: 100% 7/7 [00:00<00:00, 674.26it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: No labels found in data/labels.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/labels.cache\n",
            "Plotting labels to monkey/yolov5s_size640_epochs20_batch64_small/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mmonkey/yolov5s_size640_epochs20_batch64_small\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/19     14.2G   0.09017   0.03124         0        36       640: 100% 32/32 [10:50<00:00, 20.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  6.93it/s]\n",
            "                 all          7          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/19     14.2G   0.05882   0.02121         0        51       640: 100% 32/32 [10:47<00:00, 20.23s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  7.52it/s]\n",
            "                 all          7          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/19     14.2G   0.05028   0.01774         0        39       640: 100% 32/32 [10:48<00:00, 20.26s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  8.99it/s]\n",
            "                 all          7          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/19     14.2G   0.04159    0.0171         0        60       640: 100% 32/32 [10:44<00:00, 20.16s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  8.98it/s]\n",
            "                 all          7          0          0          0          0          0\n",
            "WARNING: no labels found in val set, can not compute metrics without labels ⚠️\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/19     14.2G   0.03742   0.01658         0       166       640:  72% 23/32 [07:50<03:04, 20.55s/it]"
          ]
        }
      ]
    }
  ]
}